name: Run LinkedIn Scraper

on:
  push:
    branches:
      - linkedin-scrapper-fixes
  schedule:
    - cron: '0 0 1 * *'
  workflow_dispatch:

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python 3.12
        uses: actions/setup-python@v3
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/linkedin-scraper/requirements.txt

      - name: Create cookies.json from secret
        run: |
          echo '${{ secrets.LINKEDIN_COOKIES_JSON }}' > ./scripts/linkedin-scraper/cookies.json
        
      - name: List matching YAML files
        run: |
          echo "Found the following C20xx files in public/department/Extras/Classes (random order):"
          ls public/department/Extras/Classes/ | grep -E '^C20[0-9]{2}(_Credit)?\.yaml$' | shuf


      - name: Run LinkedIn scraper for all class YAML files
        run: |
          set -e
          for file in $(ls public/department/Extras/Classes/ | grep -E '^C20[0-9]{2}(_Credit)?\.yaml$' | shuf); do
            echo "Running scraper for $file"
            # Run each file in a subshell so errors don't stop the loop
            (python scripts/linkedin-scraper/final_linkedin_script.py public/department/Extras/Classes/$file || echo "Error running scraper for $file, continuing...")
          done

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add -A
          git diff --cached --quiet || git commit -m "chore: update LinkedIn profiles and summaries"
          git push
